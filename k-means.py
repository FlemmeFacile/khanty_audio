#!/usr/bin/env python3
"""
Pseudo-Phoneme Extractor for Transfer Learning TTS
Based on the paper: "Transfer Learning from Speech Recognition to Text-to-Speech Synthesis Using Self-Supervised Representations"

Key features matching the paper:
- Uses block 15 hidden representations from wav2vec 2.0 (not XLS-R)
- K-means clustering with K=128 clusters (exactly as in paper)
- Merging consecutive identical cluster indices
- Designed for pre-training VITS architecture
- Supports both single-speaker and zero-shot multi-speaker TTS

Paper reference: https://arxiv.org/abs/2203.15447
"""

import os
import sys
import json
import logging
import argparse
import itertools
import joblib
import numpy as np
import torch
import librosa
import soundfile as sf
from tqdm import tqdm
from sklearn.cluster import MiniBatchKMeans
from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2Model
from collections import Counter, defaultdict
import psutil
import time
from typing import List, Dict, Tuple, Optional, Any
import warnings
warnings.filterwarnings("ignore", category=UserWarning, module="torch")
warnings.filterwarnings("ignore", category=FutureWarning, module="librosa")
warnings.filterwarnings("ignore", category=RuntimeWarning, module="librosa")

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –°–û–ì–õ–ê–°–ù–û –°–¢–ê–¢–¨–ï ---
PAPER_CONFIG = {
    # –¢–û–ß–ù–û–ï –°–û–û–¢–í–ï–¢–°–¢–í–ò–ï –°–¢–ê–¢–¨–ï: https://arxiv.org/abs/2203.15447
    "wav2vec_model": "facebook/wav2vec2-large-lv60", 
    "k_clusters": 128,  # –°—Ç–∞—Ç—å—è: "where we set K=128 for this work"
    "layer_index": 15,  # –°—Ç–∞—Ç—å—è: "hidden representation of block 15" (–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Å 1)
    "sample_rate": 16000,  # –°—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è wav2vec 2.0
    "max_duration": 30.0,  # –†–∞–∑—É–º–Ω—ã–π –ª–∏–º–∏—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    "target_rms": 0.1,  # –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –≥—Ä–æ–º–∫–æ—Å—Ç—å –¥–ª—è wav2vec
    "min_audio_duration": 0.5,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    "kmeans_batch_size": 5000,  # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–ª—è MiniBatchKMeans
    "checkpoint_interval": 1000,  # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∫–∞–∂–¥—ã–µ 1000 —Ñ–∞–π–ª–æ–≤
    "cuda_cache_interval": 100,  # –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ CUDA –∫—ç—à–∞
    "num_workers": max(1, psutil.cpu_count(logical=False) - 1)  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CPU
}

# --- –ù–ê–°–¢–†–û–ô–ö–ê –õ–û–ì–ò–†–û–í–ê–ù–ò–Ø ---
def setup_logging(output_dir: str, log_level: str = "INFO") -> logging.Logger:
    """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ —Ñ–∞–π–ª –∏ –∫–æ–Ω—Å–æ–ª—å —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∫–∞–∫ –≤ –Ω–∞—É—á–Ω—ã—Ö —Ä–∞–±–æ—Ç–∞—Ö"""
    os.makedirs(output_dir, exist_ok=True)
    log_file = os.path.join(output_dir, "pseudo_phoneme_extraction.log")
    
    # ‚úÖ –ü–û–õ–ù–ê–Ø –û–ß–ò–°–¢–ö–ê –í–°–ï–• –õ–û–ì–ì–ï–†–û–í
    for name in logging.root.manager.loggerDict:
        logging.getLogger(name).handlers = []
    
    # ‚úÖ –û–¢–ö–õ–Æ–ß–ê–ï–ú –ù–ê–°–õ–ï–î–û–í–ê–ù–ò–ï –û–¢ –ö–û–†–ù–ï–í–û–ì–û –õ–û–ì–ì–ï–†–ê
    logger = logging.getLogger("transfer_tts_pseudo_phonemes")
    logger.propagate = False  # –ö–ª—é—á–µ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ - –æ—Ç–∫–ª—é—á–∞–µ–º –Ω–∞—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Ö–µ–Ω–¥–ª–µ—Ä–æ–≤
    
    # ‚úÖ –ì–ê–†–ê–ù–¢–ò–†–û–í–ê–ù–ù–ê–Ø –û–ß–ò–°–¢–ö–ê –¢–ï–ö–£–©–ï–ì–û –õ–û–ì–ì–ï–†–ê
    logger.handlers = []
    
    logger.setLevel(getattr(logging, log_level.upper()))
    
    # –§–æ—Ä–º–∞—Ç—Ç–µ—Ä –≤ —Å—Ç–∏–ª–µ –Ω–∞—É—á–Ω–æ–π –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
    formatter = logging.Formatter(
        '[%(asctime)s] %(levelname)-8s | %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # –ö–æ–Ω—Å–æ–ª—å–Ω—ã–π —Ö–µ–Ω–¥–ª–µ—Ä
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    
    # –§–∞–π–ª–æ–≤—ã–π —Ö–µ–Ω–¥–ª–µ—Ä
    file_handler = logging.FileHandler(log_file, mode='a', encoding='utf-8')
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
    
    return logger


# --- –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò –°–û–ì–õ–ê–°–ù–û –°–¢–ê–¢–¨–ï ---
def estimate_available_memory() -> Tuple[float, float]:
    """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—É—é –ø–∞–º—è—Ç—å GPU –∏ RAM –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –±–∞—Ç—á–∏–Ω–≥–∞"""
    gpu_mem = 0.0
    if torch.cuda.is_available():
        torch.cuda.synchronize()
        gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1024**3  # –≤ GB
        allocated = torch.cuda.memory_allocated() / 1024**3
        cached = torch.cuda.memory_reserved() / 1024**3
        gpu_mem = gpu_mem - (allocated + cached) * 1.2  # –ë—É—Ñ–µ—Ä 20%
    
    ram = psutil.virtual_memory()
    ram_available = ram.available / 1024**3  # –≤ GB
    
    return max(0.0, gpu_mem), max(0.0, ram_available)


def auto_batch_size(gpu_mem: float, ram_available: float) -> int:
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–¥–±–∏—Ä–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ —Å–æ–≥–ª–∞—Å–Ω–æ –¥–æ—Å—Ç—É–ø–Ω–æ–π –ø–∞–º—è—Ç–∏
    –≠–º–ø–∏—Ä–∏—á–µ—Å–∫–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –æ—Å–Ω–æ–≤–∞–Ω—ã –Ω–∞ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–∏ –ø–∞–º—è—Ç–∏ wav2vec2-base
    """
    if gpu_mem > 0:
        # –î–ª—è GPU: ~1.2GB –Ω–∞ –±–∞—Ç—á –∏–∑ 8 —Ñ–∞–π–ª–æ–≤ –¥–ª—è wav2vec2-base
        batch_size = int(gpu_mem * 6.0)
        return min(32, max(4, batch_size))
    else:
        # –î–ª—è CPU: ~1.5GB RAM –Ω–∞ –±–∞—Ç—á –∏–∑ 4 —Ñ–∞–π–ª–æ–≤
        batch_size = int(ram_available * 2.5)
        return min(16, max(2, batch_size))


def validate_directory(path: str, create: bool = False) -> None:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –∏ –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞"""
    if not os.path.exists(path):
        if create:
            os.makedirs(path, exist_ok=True)
            logging.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {path}")
        else:
            raise ValueError(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {path}")
    
    if not os.access(path, os.R_OK | os.W_OK):
        raise PermissionError(f"‚ùå –ù–µ—Ç –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {path}")


def find_all_audio_files(root_dir: str, 
                        extensions: tuple = (".wav", ".flac", ".mp3"),
                        min_size_mb: float = 0.1) -> List[str]:
    """
    –†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ —Ä–∞–∑–º–µ—Ä—É
    –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –º–∞–ª–µ–Ω—å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –æ—à–∏–±–∫–∏ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    """
    audio_paths = []
    min_size_bytes = min_size_mb * 1024 * 1024
    
    logging.info(f"üîç –ü–æ–∏—Å–∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤ –≤ {root_dir}...")
    total_files = 0
    for root, _, files in os.walk(root_dir):
        for file in files:
            total_files += 1
            if file.lower().endswith(extensions):
                file_path = os.path.normpath(os.path.join(root, file))
                if os.path.getsize(file_path) >= min_size_bytes:
                    audio_paths.append(file_path)
    
    logging.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(audio_paths)}/{total_files} –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤")
    return audio_paths


def load_and_preprocess_audio(path: str, 
                            target_sr: int = 16000,
                            max_duration: float = 30.0,
                            target_rms: float = 0.1,
                            min_duration: float = 0.5) -> Optional[np.ndarray]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∞—É–¥–∏–æ —Ñ–∞–π–ª —Å–æ–≥–ª–∞—Å–Ω–æ best practices –¥–ª—è wav2vec 2.0
    
    Args:
        path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
        target_sr: –¶–µ–ª–µ–≤–∞—è —á–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ (16kHz –¥–ª—è wav2vec 2.0)
        max_duration: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        target_rms: –¶–µ–ª–µ–≤–æ–π RMS –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –≥—Ä–æ–º–∫–æ—Å—Ç–∏
        min_duration: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
    
    Returns:
        np.ndarray: –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∞—É–¥–∏–æ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
        try:
            audio, sr = sf.read(path, dtype='float32')
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {path} —á–µ—Ä–µ–∑ soundfile: {e}")
            # –ü–æ–ø—ã—Ç–∫–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ —á–µ—Ä–µ–∑ librosa
            audio, sr = librosa.load(path, sr=None, mono=False)
            audio = audio.astype(np.float32)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª
        if audio.size == 0:
            logging.warning(f"‚ö†Ô∏è –ü—É—Å—Ç–æ–π –∞—É–¥–∏–æ —Ñ–∞–π–ª: {path}")
            return None
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –º–æ–Ω–æ (–∫–∞–∫ –≤ —Å—Ç–∞—Ç—å–µ –æ wav2vec 2.0)
        if audio.ndim > 1:
            if audio.shape[0] > audio.shape[1]:  # –ö–∞–Ω–∞–ª—ã –≤ –ø–µ—Ä–≤–æ–º –∏–∑–º–µ—Ä–µ–Ω–∏–∏
                audio = audio.T
            audio = librosa.to_mono(audio)
        
        # –û–±—Ä–µ–∑–∫–∞ –¥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        max_samples = int(max_duration * sr)
        if len(audio) > max_samples:
            audio = audio[:max_samples]
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        if len(audio) < int(min_duration * sr):
            logging.warning(f"‚ö†Ô∏è –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ –∞—É–¥–∏–æ ({len(audio)/sr:.2f}s): {path}")
            return None
        
        # –†–µ—Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ)
        if sr != target_sr:
            audio = librosa.resample(
                audio, 
                orig_sr=sr, 
                target_sr=target_sr,
                res_type='kaiser_best'  # –õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–ª—è –∞—É–¥–∏–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            )
            logging.debug(f"üîÑ –†–µ—Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–æ {path} —Å {sr}Hz –Ω–∞ {target_sr}Hz")
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–æ–º–∫–æ—Å—Ç–∏ –ø–æ RMS (–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ –¥–ª—è wav2vec 2.0)
        current_rms = np.sqrt(np.mean(audio**2))
        if current_rms > 1e-6:  # –ò–∑–±–µ–≥–∞–µ–º –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å
            gain = target_rms / current_rms
            audio = audio * gain
            # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∞–º–ø–ª–∏—Ç—É–¥—ã –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –∫–ª–∏–ø–ø–∏–Ω–≥–∞
            audio = np.clip(audio, -0.99, 0.99)
        
        # Final validation
        if np.isnan(audio).any() or np.isinf(audio).any():
            logging.warning(f"‚ö†Ô∏è NaN/Inf –∑–Ω–∞—á–µ–Ω–∏—è –≤ –∞—É–¥–∏–æ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {path}")
            return None
        
        return audio
        
    except Exception as e:
        logging.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {path}: {str(e)}")
        return None


def safe_load_processed_paths(progress_log: str) -> set:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –ø—É—Ç–µ–π —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
    processed = set()
    if os.path.exists(progress_log):
        try:
            with open(progress_log, 'r', encoding='utf-8') as f:
                for line in f:
                    path = line.strip()
                    if path and os.path.exists(path):
                        processed.add(path)
            logging.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(processed)} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –ø—É—Ç–µ–π –∏–∑ {progress_log}")
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {progress_log}: {str(e)}")
    return processed


def safe_save_processed_path(progress_log: str, path: str) -> None:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –ø—É—Ç–∏"""
    try:
        dir_path = os.path.dirname(progress_log)
        if dir_path and not os.path.exists(dir_path):
            os.makedirs(dir_path, exist_ok=True)
        
        with open(progress_log, 'a', encoding='utf-8') as f:
            f.write(path + '\n')
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ {path} –≤ {progress_log}: {str(e)}")


def check_existing_records(filelist_path: str) -> Dict[str, str]:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∑–∞–ø–∏—Å–∏ –≤ —Ñ–∞–π–ª–ª–∏—Å—Ç–µ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
    existing = {}
    if os.path.exists(filelist_path):
        try:
            with open(filelist_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    parts = line.split('|')
                    if len(parts) >= 2:
                        audio_path = parts[0]
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
                        if os.path.exists(audio_path):
                            existing[audio_path] = line
            logging.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(existing)} —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π –≤ {filelist_path}")
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {filelist_path}: {str(e)}")
    return existing


# --- –û–°–ù–û–í–ù–´–ï –§–£–ù–ö–¶–ò–ò –°–û–ì–õ–ê–°–ù–û –°–¢–ê–¢–¨–ï ---
def train_kmeans_incremental(
    audio_paths: List[str],
    processor: Wav2Vec2FeatureExtractor,
    model: Wav2Vec2Model,
    target_layer: int,
    k: int,
    extraction_batch_size: int = 8,
    kmeans_batch_size: int = 5000,
    checkpoint_path: str = None,
    checkpoint_interval: int = 1000,
    cuda_cache_interval: int = 100,
    device: str = "cuda",
    logger: logging.Logger = None,
    start_from_index: int = 0  # –ù–û–í–´–ô –ü–ê–†–ê–ú–ï–¢–†: —Å –∫–∞–∫–æ–≥–æ —Ñ–∞–π–ª–∞ –Ω–∞—á–∏–Ω–∞—Ç—å
) -> MiniBatchKMeans:
    logger = logger or logging.getLogger("transfer_tts_pseudo_phonemes")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—É—Ç–µ–π –∫ —á–µ–∫–ø–æ–∏–Ω—Ç–∞–º
    temp_checkpoint_path = None
    if checkpoint_path:
        checkpoint_dir = os.path.dirname(checkpoint_path)
        temp_checkpoint_path = os.path.join(checkpoint_dir, "kmeans_temp_checkpoint.joblib")
    
    # –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —á–µ–∫–ø–æ–∏–Ω—Ç–∞
    loaded_kmeans = None
    if temp_checkpoint_path and os.path.exists(temp_checkpoint_path):
        try:
            logger.info(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —á–µ–∫–ø–æ–∏–Ω—Ç–∞: {temp_checkpoint_path}")
            loaded_kmeans = joblib.load(temp_checkpoint_path)
            logger.info(f"‚úÖ –í—Ä–µ–º–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å K-means –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —á–µ–∫–ø–æ–∏–Ω—Ç–∞: {str(e)}")
    
    # –ï—Å–ª–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —á–µ–∫–ø–æ–∏–Ω—Ç –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω, –ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–π
    if not loaded_kmeans and checkpoint_path and os.path.exists(checkpoint_path):
        try:
            logger.info(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ K-means: {checkpoint_path}")
            loaded_kmeans = joblib.load(checkpoint_path)
            logger.info(f"‚úÖ –§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å K-means –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –û–±—É—á–µ–Ω–∏–µ —É–∂–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
            return loaded_kmeans  # –û–±—É—á–µ–Ω–∏–µ —É–∂–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏: {str(e)}")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ K-means
    if loaded_kmeans:
        kmeans = loaded_kmeans
        logger.info(f"üìä –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è —Å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏.")
    else:
        logger.info(f"üéØ –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è K-means —Å –Ω—É–ª—è")
        kmeans = MiniBatchKMeans(
            n_clusters=k,
            random_state=42,
            batch_size=kmeans_batch_size,
            n_init="auto",
            verbose=0,
            reassignment_ratio=0.01,
            max_iter=100
        )
    
    total_features = 0
    processed_files = start_from_index  # –ù–∞—á–∏–Ω–∞–µ–º —Å —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
    start_time = time.time()
    last_checkpoint_time = start_time
    
    logger.info(f"üöÄ –ó–∞–ø—É—Å–∫/–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è...")
    logger.info(f"   ‚Ä¢ –ù–∞—á–∏–Ω–∞–µ–º —Å —Ñ–∞–π–ª–∞: {start_from_index}")
    logger.info(f"   ‚Ä¢ –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {len(audio_paths)}")
    
    try:
        # –ü–†–û–î–û–õ–ñ–ê–ï–ú –° –¢–û–ì–û –ú–ï–°–¢–ê, –ù–ê –ö–û–¢–û–†–û–ú –û–°–¢–ê–ù–û–í–ò–õ–ò–°–¨
        for i in tqdm(range(start_from_index, len(audio_paths), extraction_batch_size), 
                     desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ –¥–ª—è K-Means", 
                     unit="batch"):
            
            batch_paths = audio_paths[i:i + extraction_batch_size]
            batch_features = []
            batch_success_count = 0
            
            for path in batch_paths:
                audio = load_and_preprocess_audio(
                    path,
                    target_sr=PAPER_CONFIG["sample_rate"],
                    max_duration=PAPER_CONFIG["max_duration"],
                    target_rms=PAPER_CONFIG["target_rms"],
                    min_duration=PAPER_CONFIG["min_audio_duration"]
                )
                
                if audio is None or len(audio) < 320:
                    continue
                
                try:
                    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                    max_length = int(PAPER_CONFIG["max_duration"] * PAPER_CONFIG["sample_rate"])
                    inputs = processor(
                        audio,
                        sampling_rate=PAPER_CONFIG["sample_rate"],
                        return_tensors="pt",
                        padding=True,
                        truncation=True,
                        max_length=max_length
                    ).input_values.to(device)
                    
                    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                    with torch.no_grad():
                        outputs = model(inputs, output_hidden_states=True)
                        
                        if target_layer >= len(outputs.hidden_states):
                            logger.error(f"‚ùå –ó–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–π —Å–ª–æ–π {target_layer} –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç.")
                            raise ValueError(f"Invalid layer index: {target_layer}")
                        
                        hidden_state = outputs.hidden_states[target_layer]
                        hidden_state = hidden_state / torch.norm(hidden_state, dim=2, keepdim=True)
                        batch_features.append(hidden_state.cpu().numpy())
                        batch_success_count += 1
                        
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {path}: {str(e)}")
                    continue
            
            # –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –±–∞—Ç—á–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            if batch_features:
                try:
                    X_batch = np.concatenate([feats.reshape(-1, feats.shape[2]) for feats in batch_features], axis=0)
                    kmeans.partial_fit(X_batch)
                    total_features += X_batch.shape[0]
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –Ω–∞ –±–∞—Ç—á–µ: {str(e)}")
            
            processed_files += len(batch_paths)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 100 —Ñ–∞–π–ª–æ–≤
            if processed_files % 100 == 0:
                try:
                    # progress_file –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –¥–æ—Å—Ç—É–ø–µ–Ω –≤ —ç—Ç–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
                    # –ú–æ–∂–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å –µ–≥–æ –∫–∞–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π –ø—É—Ç—å
                    progress_file = os.path.join(os.path.dirname(checkpoint_path), "kmeans_progress.txt")
                    with open(progress_file, 'w') as f:
                        f.write(str(processed_files))
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å: {e}")

            # –û—á–∏—Å—Ç–∫–∞ CUDA –∫—ç—à–∞
            if device == "cuda" and processed_files % cuda_cache_interval == 0:
                torch.cuda.empty_cache()
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–∞
            if temp_checkpoint_path and processed_files % checkpoint_interval == 0:
                try:
                    current_time = time.time()
                    elapsed_since_last = current_time - last_checkpoint_time
                    
                    logger.info(f"üíæ –ß–µ–∫–ø–æ–∏–Ω—Ç ({processed_files}/{len(audio_paths)} —Ñ–∞–π–ª–æ–≤)")
                    joblib.dump(kmeans, temp_checkpoint_path)
                    last_checkpoint_time = current_time
                    
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —á–µ–∫–ø–æ–∏–Ω—Ç–∞: {str(e)}")
            
            # –ü—Ä–æ–≥—Ä–µ—Å—Å
            if processed_files % 100 == 0:
                elapsed = time.time() - start_time
                features_per_sec = total_features / elapsed if elapsed > 0 else 0
                logger.info(f"üìà –ü—Ä–æ–≥—Ä–µ—Å—Å: {processed_files}/{len(audio_paths)} —Ñ–∞–π–ª–æ–≤ | {features_per_sec:.1f} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤/—Å–µ–∫")
        
        # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        if checkpoint_path and total_features > 0:
            try:
                logger.info("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ K-means...")
                joblib.dump(kmeans, checkpoint_path)
                logger.info(f"‚úÖ –§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {checkpoint_path}")
                
                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —á–µ–∫–ø–æ–∏–Ω—Ç
                if temp_checkpoint_path and os.path.exists(temp_checkpoint_path):
                    os.remove(temp_checkpoint_path)
                    logger.debug("üßπ –£–¥–∞–ª–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —á–µ–∫–ø–æ–∏–Ω—Ç")
                    
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏: {str(e)}")
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        elapsed = time.time() - start_time
        logger.info(f"\nüéâ –û–ë–£–ß–ï–ù–ò–ï K-MEANS –ó–ê–í–ï–†–®–ï–ù–û!")
        logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {processed_files:,}/{len(audio_paths):,}")
        logger.info(f"üìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {total_features:,}")
        logger.info(f"üìä –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {elapsed/60:.1f} –º–∏–Ω—É—Ç")
        
        return kmeans
        
    except KeyboardInterrupt:
        logger.warning("\nüõë –û–±—É—á–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º!")
        if temp_checkpoint_path and hasattr(kmeans, 'cluster_centers_'):
            try:
                logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞...")
                joblib.dump(kmeans, temp_checkpoint_path)
                logger.info(f"‚úÖ –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {temp_checkpoint_path}")
                logger.info(f"üìå –ß—Ç–æ–±—ã –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å, –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç —Å–Ω–æ–≤–∞ –ë–ï–ó --force_retrain")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –ø—Ä–µ—Ä–≤–∞–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è: {str(e)}")
        raise
    
    except Exception as e:
        logger.exception(f"üî• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏: {str(e)}")
        raise

def generate_pseudophones_filelist(
    audio_paths: List[str],
    processor: Wav2Vec2FeatureExtractor,
    model: Wav2Vec2Model,
    kmeans: MiniBatchKMeans,
    target_layer: int,
    output_path: str,
    speaker_id: str = "speaker_01",
    extraction_batch_size: int = 8,
    cuda_cache_interval: int = 100,
    device: str = "cuda",
    logger: logging.Logger = None
) -> Dict[str, Any]:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∞–π–ª–∞ —Å –ø—Å–µ–≤–¥–æ-—Ñ–æ–Ω–µ–º–Ω—ã–º–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º–∏ —Å–æ–≥–ª–∞—Å–Ω–æ —Å—Ç–∞—Ç—å–µ
    
    –°–û–û–¢–í–ï–¢–°–¢–í–ò–ï –°–¢–ê–¢–¨–ï:
    - "the same consecutive indices are merged to reflect the characteristics of a real phoneme"
    - "We refer to these merged indices i'1, ..., i'T' as pseudo phoneme"
    - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è pre-training VITS –∫–∞–∫ substitute of phoneme sequences
    
    Args:
        audio_paths: –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞–º
        processor: Wav2Vec2FeatureExtractor
        model: Wav2Vec2Model
        kmeans: –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å K-means
        target_layer: –ò–Ω–¥–µ–∫—Å —Å–ª–æ—è (15 –¥–ª—è block 15)
        output_path: –ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
        speaker_id: ID —Å–ø–∏–∫–µ—Ä–∞ –¥–ª—è –≤—Å–µ—Ö –∑–∞–ø–∏—Å–µ–π
        extraction_batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        cuda_cache_interval: –ò–Ω—Ç–µ—Ä–≤–∞–ª –æ—á–∏—Å—Ç–∫–∏ CUDA –∫—ç—à–∞
        device: –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
        logger: –õ–æ–≥–≥–µ—Ä
    """
    logger = logger or logging.getLogger("transfer_tts_pseudo_phonemes")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    existing_records = check_existing_records(output_path)
    processed_paths = safe_load_processed_paths(output_path + ".progress")
    
    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    new_audio_paths = [
        path for path in audio_paths 
        if path not in processed_paths and path not in existing_records
    ]
    
    logger.info(f"üéØ –ù–∞—á–∞–ª–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Å–µ–≤–¥–æ-—Ñ–æ–Ω–µ–º–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π")
    logger.info(f"üìä –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:")
    logger.info(f"   ‚Ä¢ –¶–µ–ª–µ–≤–æ–π —Å–ª–æ–π: block {target_layer}")
    logger.info(f"   ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {kmeans.n_clusters}")
    logger.info(f"   ‚Ä¢ ID —Å–ø–∏–∫–µ—Ä–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {speaker_id}")
    logger.info(f"   ‚Ä¢ –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {len(audio_paths):,}")
    logger.info(f"   ‚Ä¢ –£–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(processed_paths):,}")
    logger.info(f"   ‚Ä¢ –£–∂–µ –≤ —Ñ–∞–π–ª–ª–∏—Å—Ç–µ: {len(existing_records):,}")
    logger.info(f"   ‚Ä¢ –ù–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(new_audio_paths):,}")
    
    if not new_audio_paths:
        logger.warning("‚ö†Ô∏è –ù–µ—Ç –Ω–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        return {
            "total_records": len(existing_records),
            "new_records": 0,
            "error_count": 0
        }
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    output_dir = os.path.dirname(output_path)
    os.makedirs(output_dir, exist_ok=True)
    
    # –ï—Å–ª–∏ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ –Ω–µ –ø—É—Å—Ç–æ–π, –æ—Ç–∫—Ä—ã–≤–∞–µ–º –≤ —Ä–µ–∂–∏–º–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
    file_mode = 'a' if os.path.exists(output_path) and os.path.getsize(output_path) > 0 else 'w'
    
    stats = {
        "total_new_records": 0,
        "error_count": 0,
        "sequence_lengths": [],
        "cluster_usage": Counter(),
        "start_time": time.time(),
        "success_files": [],
        "error_files": []
    }
    
    try:
        with open(output_path, file_mode, encoding='utf-8') as f_out:
            logger.info(f"üìù –û—Ç–∫—Ä—ã—Ç —Ñ–∞–π–ª –¥–ª—è –∑–∞–ø–∏—Å–∏: {output_path} (—Ä–µ–∂–∏–º: {file_mode})")
            
            for i in tqdm(range(0, len(new_audio_paths), extraction_batch_size), 
                         desc="–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Å–µ–≤–¥–æ-—Ñ–æ–Ω–µ–º", 
                         unit="batch",
                         total=len(new_audio_paths)//extraction_batch_size + 1):
                
                batch_paths = new_audio_paths[i:i + extraction_batch_size]
                
                for path in batch_paths:
                    try:
                        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ
                        audio = load_and_preprocess_audio(
                            path,
                            target_sr=PAPER_CONFIG["sample_rate"],
                            max_duration=PAPER_CONFIG["max_duration"],
                            target_rms=PAPER_CONFIG["target_rms"],
                            min_duration=PAPER_CONFIG["min_audio_duration"]
                        )
                        
                        if audio is None:
                            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∞—É–¥–∏–æ: {path}")
                            stats["error_count"] += 1
                            stats["error_files"].append(path)
                            safe_save_processed_path(output_path + ".progress", path)
                            continue
                        
                        # –í–ê–ñ–ù–û: –£–∫–∞–∑—ã–≤–∞–µ–º max_length –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –æ—à–∏–±–∫–∏ —Å truncation=True
                        max_length = int(PAPER_CONFIG["max_duration"] * PAPER_CONFIG["sample_rate"])
                        
                        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                        inputs = processor(
                            audio,
                            sampling_rate=PAPER_CONFIG["sample_rate"],
                            return_tensors="pt",
                            padding=True,
                            truncation=True,
                            max_length=max_length  # –î–æ–±–∞–≤–ª—è–µ–º —è–≤–Ω–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ max_length
                        ).input_values.to(device)
                        
                        with torch.no_grad():
                            outputs = model(inputs, output_hidden_states=True)
                            
                            # –°–û–û–¢–í–ï–¢–°–¢–í–ò–ï –°–¢–ê–¢–¨–ï: block 15 hidden representations
                            hidden_state = outputs.hidden_states[target_layer]
                            
                            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è (–∫–∞–∫ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ K-means)
                            hidden_state = hidden_state / torch.norm(
                                hidden_state, dim=2, keepdim=True
                            )
                            
                            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
                            features = hidden_state.cpu().numpy().reshape(-1, hidden_state.shape[2])
                            cluster_ids = kmeans.predict(features)
                            
                            # –°–û–û–¢–í–ï–¢–°–¢–í–ò–ï –°–¢–ê–¢–¨–ï: "the same consecutive indices are merged"
                            merged_ids = [key for key, _ in itertools.groupby(cluster_ids)]
                            
                            if not merged_ids:  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
                                logger.warning(f"‚ö†Ô∏è –ü—É—Å—Ç–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ—Å–ª–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –¥–ª—è {path}")
                                stats["error_count"] += 1
                                stats["error_files"].append(path)
                                safe_save_processed_path(output_path + ".progress", path)
                                continue
                            
                            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ VITS
                            pseudo_phoneme_str = " ".join(map(str, merged_ids))
                            record = f"{path}|{pseudo_phoneme_str}|{speaker_id}\n"
                            
                            # –ó–∞–ø–∏—Å—å –≤ —Ñ–∞–π–ª
                            f_out.write(record)
                            f_out.flush()
                            
                            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                            stats["total_new_records"] += 1
                            stats["success_files"].append(path)
                            stats["sequence_lengths"].append(len(merged_ids))
                            stats["cluster_usage"].update(merged_ids)
                            
                            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∫–∞–∂–¥—ã–µ 100 –∑–∞–ø–∏—Å–µ–π
                            if stats["total_new_records"] % 100 == 0:
                                avg_len = np.mean(stats["sequence_lengths"])
                                logger.info(
                                    f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {stats['total_new_records']:,} | "
                                    f"–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞: {avg_len:.1f} | "
                                    f"–û—à–∏–±–æ–∫: {stats['error_count']}"
                                )
                        
                    except Exception as e:
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {path}: {str(e)}")
                        stats["error_count"] += 1
                        stats["error_files"].append(path)
                    
                    finally:
                        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞
                        safe_save_processed_path(output_path + ".progress", path)
                        
                        # –û—á–∏—Å—Ç–∫–∞ CUDA –∫—ç—à–∞ —Å –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º
                        if device == "cuda" and stats["total_new_records"] % cuda_cache_interval == 0:
                            torch.cuda.empty_cache()
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        elapsed = time.time() - stats["start_time"]
        logger.info(f"\nüéâ ‚úÖ –ì–ï–ù–ï–†–ê–¶–ò–Ø –ü–°–ï–í–î–û-–§–û–ù–ï–ú –ó–ê–í–ï–†–®–ï–ù–ê!")
        
        if stats["sequence_lengths"]:
            mean_len = float(np.mean(stats["sequence_lengths"]))
            std_len = float(np.std(stats["sequence_lengths"]))
            min_len = int(min(stats["sequence_lengths"]))
            max_len = int(max(stats["sequence_lengths"]))
            
            logger.info(f"üìä –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
            logger.info(f"   ‚Ä¢ –ù–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π: {stats['total_new_records']:,}")
            logger.info(f"   ‚Ä¢ –û—à–∏–±–æ–∫: {stats['error_count']:,}")
            logger.info(f"   ‚Ä¢ –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {elapsed/60:.1f} –º–∏–Ω—É—Ç")
            logger.info(f"   ‚Ä¢ –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {mean_len:.1f} ¬± {std_len:.1f}")
            logger.info(f"   ‚Ä¢ –î–∏–∞–ø–∞–∑–æ–Ω –¥–ª–∏–Ω: {min_len} - {max_len}")
            logger.info(f"   ‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {len(stats['cluster_usage'])}/{kmeans.n_clusters}")
            
            # –¢–æ–ø-10 –Ω–∞–∏–±–æ–ª–µ–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
            top_clusters = stats["cluster_usage"].most_common(10)
            logger.info(f"   ‚Ä¢ –¢–æ–ø-10 –∫–ª–∞—Å—Ç–µ—Ä–æ–≤:")
            for rank, (cid, count) in enumerate(top_clusters, 1):
                percentage = (count / sum(stats["cluster_usage"].values())) * 100
                logger.info(f"      {rank}. –ö–ª–∞—Å—Ç–µ—Ä {cid}: {count:,} —Ä–∞–∑ ({percentage:.1f}%)")
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            stats_path = os.path.join(output_dir, "pseudo_phoneme_stats.json")
            final_stats = {
                "paper_reference": "https://arxiv.org/abs/2203.15447",
                "configuration": {
                    "wav2vec_model": model.config._name_or_path,
                    "layer_index": target_layer,
                    "k_clusters": kmeans.n_clusters,
                    "sample_rate": PAPER_CONFIG["sample_rate"],
                    "max_duration": PAPER_CONFIG["max_duration"]
                },
                "processing_stats": {
                    "total_files_processed": len(new_audio_paths),
                    "successful_files": stats["total_new_records"],
                    "error_files": stats["error_count"],
                    "success_rate": (stats["total_new_records"] / len(new_audio_paths)) * 100 if new_audio_paths else 0,
                    "processing_time_seconds": elapsed,
                    "processing_time_minutes": elapsed/60,
                    "average_sequence_length": mean_len,
                    "std_sequence_length": std_len,
                    "min_sequence_length": min_len,
                    "max_sequence_length": max_len
                },
                "cluster_usage": {
                    "unique_clusters_used": len(stats["cluster_usage"]),
                    "total_clusters": kmeans.n_clusters,
                    "usage_percentage": (len(stats["cluster_usage"]) / kmeans.n_clusters) * 100,
                    "top_10_clusters": {str(cid): count for cid, count in top_clusters},
                    "cluster_distribution": {str(cid): count for cid, count in stats["cluster_usage"].most_common()}
                },
                "file_lists": {
                    "successful_files": stats["success_files"][:100],  # –ü–µ—Ä–≤—ã–µ 100 –¥–ª—è –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è
                    "error_files": stats["error_files"][:100],
                    "total_successful": len(stats["success_files"]),
                    "total_errors": len(stats["error_files"])
                },
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                "note": "–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ –∏–∑ —Å—Ç–∞—Ç—å–∏: 'Transfer Learning from Speech Recognition to Text-to-Speech Synthesis Using Self-Supervised Representations'"
            }
            
            try:
                with open(stats_path, 'w', encoding='utf-8') as f:
                    json.dump(final_stats, f, indent=2, ensure_ascii=False)
                logger.info(f"‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {stats_path}")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {str(e)}")
        
        return {
            "total_records": stats["total_new_records"] + len(existing_records),
            "new_records": stats["total_new_records"],
            "error_count": stats["error_count"],
            "stats_path": stats_path if 'stats_path' in locals() else None
        }
    
    except KeyboardInterrupt:
        logger.warning("\nüõë –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º!")
        elapsed = time.time() - stats["start_time"]
        logger.info(
            f"‚ö†Ô∏è –ß–∞—Å—Ç–∏—á–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {stats['total_new_records']:,} –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π –∑–∞ {elapsed/60:.1f} –º–∏–Ω—É—Ç"
        )
        raise
    
    except Exception as e:
        logger.exception(f"üî• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {str(e)}")
        raise


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å –ø–æ–ª–Ω—ã–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ–º —Å—Ç–∞—Ç—å–µ"""
    parser = argparse.ArgumentParser(
        description="Pseudo-Phoneme Extractor for Transfer Learning TTS",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
        epilog="Based on the paper: 'Transfer Learning from Speech Recognition to Text-to-Speech Synthesis Using Self-Supervised Representations' (https://arxiv.org/abs/2203.15447)"
    )
    
    parser.add_argument(
        "mode", 
        choices=["train_kmeans", "generate_pseudophones"],
        help="–†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã: –æ–±—É—á–µ–Ω–∏–µ K-means –∏–ª–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Å–µ–≤–¥–æ-—Ñ–æ–Ω–µ–º"
    )
    
    parser.add_argument(
        "--audio_dir",
        required=True,
        help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞–º–∏ (—Ä–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫)"
    )
    
    parser.add_argument(
        "--output_dir",
        default="outputs",
        help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"
    )
    
    parser.add_argument(
        "--sample_files",
        type=int,
        default=0,
        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (0 = –≤—Å–µ)"
    )
    
    parser.add_argument(
        "--k_clusters",
        type=int,
        default=PAPER_CONFIG["k_clusters"],
        help=f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –¥–ª—è K-means (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {PAPER_CONFIG['k_clusters']}, –∫–∞–∫ –≤ —Å—Ç–∞—Ç—å–µ)"
    )
    
    parser.add_argument(
        "--layer_index",
        type=int,
        default=PAPER_CONFIG["layer_index"],
        help=f"–ò–Ω–¥–µ–∫—Å —Å–ª–æ—è wav2vec2 –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {PAPER_CONFIG['layer_index']} –¥–ª—è block 15, –∫–∞–∫ –≤ —Å—Ç–∞—Ç—å–µ)"
    )
    
    parser.add_argument(
        "--speaker_id",
        default="speaker_01",
        help="ID —Å–ø–∏–∫–µ—Ä–∞ –¥–ª—è –≤—Å–µ—Ö –∑–∞–ø–∏—Å–µ–π (–¥–ª—è multi-speaker –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–∞–∑–Ω—ã–µ ID)"
    )
    
    parser.add_argument(
        "--wav2vec_model",
        default=PAPER_CONFIG["wav2vec_model"],
        help=f"–ú–æ–¥–µ–ª—å wav2vec2 –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {PAPER_CONFIG['wav2vec_model']}, –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π wav2vec 2.0 –∫–∞–∫ –≤ —Å—Ç–∞—Ç—å–µ)"
    )
    
    parser.add_argument(
        "--log_level",
        default="INFO",
        choices=["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"],
        help="–£—Ä–æ–≤–µ–Ω—å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"
    )
    
    parser.add_argument(
        "--force_retrain",
        action="store_true",
        help="–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ K-means –¥–∞–∂–µ –µ—Å–ª–∏ –º–æ–¥–µ–ª—å —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"
    )
    
    args = parser.parse_args()
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –≤—ã—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    os.makedirs(args.output_dir, exist_ok=True)
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logger = setup_logging(args.output_dir, args.log_level)
    
    # –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å—Ç–∞—Ç—å–µ
    logger.info("\n" + "="*60)
    logger.info("üìö PSEUDO-PHONEME EXTRACTOR FOR TRANSFER LEARNING TTS")
    logger.info("="*60)
    logger.info("üìÑ –û—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ —Å—Ç–∞—Ç—å–µ:")
    logger.info("   'Transfer Learning from Speech Recognition to Text-to-Speech Synthesis'")
    logger.info("   'Using Self-Supervised Representations'")
    logger.info("   https://arxiv.org/abs/2203.15447")
    logger.info("")
    logger.info("üéØ –ö–ª—é—á–µ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ —Å—Ç–∞—Ç—å–∏:")
    logger.info(f"   ‚Ä¢ –ú–æ–¥–µ–ª—å wav2vec 2.0: {PAPER_CONFIG['wav2vec_model']}")
    logger.info(f"   ‚Ä¢ –°–ª–æ–π –¥–ª—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: block {PAPER_CONFIG['layer_index']} (hidden representation of block 15)")
    logger.info(f"   ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {PAPER_CONFIG['k_clusters']} (K=128)")
    logger.info(f"   ‚Ä¢ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")
    logger.info("")
    logger.info(f"‚öôÔ∏è  –¢–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º: {args.mode}")
    logger.info(f"üìÇ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –∞—É–¥–∏–æ: {args.audio_dir}")
    logger.info(f"üìÇ –í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {args.output_dir}")
    logger.info("="*60 + "\n")
    
    try:
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
        validate_directory(args.audio_dir, create=False)
        validate_directory(args.output_dir, create=True)
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        device = "cuda" if torch.cuda.is_available() else "cpu"
        logger.info(f"üíª –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
        
        if device == "cuda":
            gpu_mem, ram_available = estimate_available_memory()
            logger.info(f"üìä –î–æ—Å—Ç—É–ø–Ω–æ GPU –ø–∞–º—è—Ç–∏: {gpu_mem:.1f} GB")
            logger.info(f"üìä –î–æ—Å—Ç—É–ø–Ω–æ RAM: {ram_available:.1f} GB")
            
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥–±–æ—Ä —Ä–∞–∑–º–µ—Ä–∞ –±–∞—Ç—á–∞
            auto_batch = auto_batch_size(gpu_mem, ram_available)
            extraction_batch_size = min(32, max(4, auto_batch))
            logger.info(f"‚ö° –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–¥–æ–±—Ä–∞–Ω —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {extraction_batch_size}")
        else:
            extraction_batch_size = 4
            logger.warning("‚ö†Ô∏è GPU –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU. –°–∫–æ—Ä–æ—Å—Ç—å –±—É–¥–µ—Ç –Ω–∏–∂–µ.")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤
        audio_paths = find_all_audio_files(args.audio_dir)
        
        if args.sample_files > 0 and args.sample_files < len(audio_paths):
            audio_paths = audio_paths[:args.sample_files]
            logger.info(f"üß™ –†–µ–∂–∏–º –≤—ã–±–æ—Ä–∫–∏: –æ–±—Ä–∞–±–æ—Ç–∫–∞ {len(audio_paths)} —Ñ–∞–π–ª–æ–≤")
        
        if not audio_paths:
            logger.error("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏!")
            sys.exit(1)
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ wav2vec2
        logger.info(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ {args.wav2vec_model} –Ω–∞ {device}...")
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
        if "xls-r" in args.wav2vec_model.lower():
            logger.warning("‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –í—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ XLS-R –º–æ–¥–µ–ª—å –≤–º–µ—Å—Ç–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ wav2vec 2.0")
            logger.warning("‚ö†Ô∏è –°—Ç–∞—Ç—å—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç facebook/wav2vec2-base-960h (–æ–±—É—á–µ–Ω–Ω—ã–π –Ω–∞ 960h –∞–Ω–≥–ª–∏–π—Å–∫–æ–π —Ä–µ—á–∏)")
            logger.warning("‚ö†Ô∏è –î–ª—è —Ñ–∏–Ω—Å–∫–æ–≥–æ —è–∑—ã–∫–∞ —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–¥–æ–ø—Ç–∏–º–∞–ª—å–Ω–æ, –Ω–æ –ø—Ä–∏–µ–º–ª–µ–º–æ –¥–ª—è transfer learning")
        
        processor = Wav2Vec2FeatureExtractor.from_pretrained(args.wav2vec_model)
        model = Wav2Vec2Model.from_pretrained(args.wav2vec_model).to(device)
        model.eval()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ª–æ–µ–≤ –≤ –º–æ–¥–µ–ª–∏
        dummy_input = torch.randn(1, 16000).to(device)
        with torch.no_grad():
            dummy_output = model(dummy_input, output_hidden_states=True)
        num_layers = len(dummy_output.hidden_states) - 1  # -1 –ø–æ—Ç–æ–º—É —á—Ç–æ 0-–π —Å–ª–æ–π —ç—Ç–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
        logger.info(f"üîç –ú–æ–¥–µ–ª—å —Å–æ–¥–µ—Ä–∂–∏—Ç {num_layers} —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ–µ–≤")
        
        if args.layer_index > num_layers:
            logger.warning(f"‚ö†Ô∏è –ó–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–π —Å–ª–æ–π {args.layer_index} –ø—Ä–µ–≤—ã—à–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å–ª–æ–µ–≤ ({num_layers})")
            logger.warning(f"‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ—Å–ª–µ–¥–Ω–∏–π –¥–æ—Å—Ç—É–ø–Ω—ã–π —Å–ª–æ–π: {num_layers}")
            args.layer_index = num_layers
        
        logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–ª–æ–π: {args.layer_index}")
        
        # –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
        kmeans_path = os.path.join(args.output_dir, "kmeans_model.joblib")
        filelist_path = os.path.join(args.output_dir, "finnish_pseudo_for_vits.txt")
        progress_log = filelist_path + ".progress"
        
        if args.mode == "train_kmeans":
            logger.info("\n" + "="*60)
            logger.info("üéØ –≠–¢–ê–ü 1: –û–ë–£–ß–ï–ù–ò–ï K-MEANS –ù–ê –°–ö–†–´–¢–´–• –ü–†–ï–î–°–¢–ê–í–õ–ï–ù–ò–Ø–•")
            logger.info("="*60)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —Å –∫–∞–∫–æ–≥–æ —Ñ–∞–π–ª–∞ –Ω–∞—á–∏–Ω–∞—Ç—å
            progress_file = os.path.join(args.output_dir, "kmeans_progress.txt")
            start_from_index = 0
            
            # –ï—Å–ª–∏ –Ω–µ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ –∏ –µ—Å—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å - –∑–∞–≥—Ä—É–∂–∞–µ–º
            if not args.force_retrain and os.path.exists(progress_file):
                try:
                    with open(progress_file, 'r') as f:
                        start_from_index = int(f.read().strip())
                    logger.info(f"üìå –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è —Å —Ñ–∞–π–ª–∞ #{start_from_index}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª –ø—Ä–æ–≥—Ä–µ—Å—Å–∞: {e}. –ù–∞—á–∏–Ω–∞–µ–º —Å –Ω–∞—á–∞–ª–∞.")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
            if os.path.exists(kmeans_path) and not args.force_retrain:
                logger.warning(f"‚ö†Ô∏è –§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å K-means —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {kmeans_path}")
                user_input = input("–ü–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –º–æ–¥–µ–ª—å? (y/n): ").strip().lower()
                if user_input != 'y':
                    logger.info("‚è≠Ô∏è  –û–±—É—á–µ–Ω–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                    sys.exit(0)
            
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-—Ñ–∞–π–ª –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è
            def save_progress(current_index):
                try:
                    with open(progress_file, 'w') as f:
                        f.write(str(current_index))
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å: {e}")
            
            # –û–±—É—á–µ–Ω–∏–µ K-means
            logger.info("üöÄ –ó–∞–ø—É—Å–∫/–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è K-means...")
            
            # –ö–æ–¥ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –≤–Ω—É—Ç—Ä–∏ train_kmeans_incremental
            # –î–æ–±–∞–≤—å—Ç–µ —ç—Ç–æ—Ç callback –≤ —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è –ø–æ—Å–ª–µ processed_files += len(batch_paths)
            def progress_callback(processed_files):
                if processed_files % 100 == 0:
                    save_progress(processed_files)
            
            # –í—ã–∑–æ–≤ –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
            kmeans = train_kmeans_incremental(
                audio_paths=audio_paths,
                processor=processor,
                model=model,
                target_layer=args.layer_index,
                k=args.k_clusters,
                extraction_batch_size=extraction_batch_size,
                kmeans_batch_size=PAPER_CONFIG["kmeans_batch_size"],
                checkpoint_path=kmeans_path,
                checkpoint_interval=PAPER_CONFIG["checkpoint_interval"],
                cuda_cache_interval=PAPER_CONFIG["cuda_cache_interval"],
                device=device,
                logger=logger,
                start_from_index=start_from_index
            )
            
            # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
            if os.path.exists(progress_file):
                os.remove(progress_file)
                logger.debug("üßπ –£–¥–∞–ª–µ–Ω —Ñ–∞–π–ª –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è")
            
            logger.info(f"‚úÖ ‚úÖ –ú–æ–¥–µ–ª—å K-means —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {kmeans_path}")
        
        elif args.mode == "generate_pseudophones":
            logger.info("\n" + "="*60)
            logger.info("üéØ –≠–¢–ê–ü 2: –ì–ï–ù–ï–†–ê–¶–ò–Ø –ü–°–ï–í–î–û-–§–û–ù–ï–ú–ù–´–• –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û–°–¢–ï–ô")
            logger.info("="*60)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –º–æ–¥–µ–ª–∏ K-means
            if not os.path.exists(kmeans_path):
                logger.error(f"‚ùå –ú–æ–¥–µ–ª—å K-means –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {kmeans_path}")
                logger.error("–°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ —Ä–µ–∂–∏–º 'train_kmeans'")
                logger.error(f"–ö–æ–º–∞–Ω–¥–∞: python {os.path.basename(__file__)} train_kmeans --audio_dir {args.audio_dir} --output_dir {args.output_dir}")
                sys.exit(1)
            
            logger.info(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ K-means –∏–∑: {kmeans_path}")
            try:
                kmeans = joblib.load(kmeans_path)
                logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å K-means –∑–∞–≥—Ä—É–∂–µ–Ω–∞, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {kmeans.n_clusters}")
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
                if kmeans.n_clusters != args.k_clusters:
                    logger.warning(f"‚ö†Ô∏è –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ ({kmeans.n_clusters}) –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–º ({args.k_clusters})")
                    logger.warning(f"‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏: {kmeans.n_clusters}")
            except Exception as e:
                logger.exception(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏ K-means: {str(e)}")
                sys.exit(1)
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Å–µ–≤–¥–æ-—Ñ–æ–Ω–µ–º
            stats = generate_pseudophones_filelist(
                audio_paths=audio_paths,
                processor=processor,
                model=model,
                kmeans=kmeans,
                target_layer=args.layer_index,
                output_path=filelist_path,
                speaker_id=args.speaker_id,
                extraction_batch_size=extraction_batch_size,
                cuda_cache_interval=PAPER_CONFIG["cuda_cache_interval"],
                device=device,
                logger=logger
            )
            
            logger.info(f"\n‚úÖ ‚úÖ –§–∞–π–ª —Å –ø—Å–µ–≤–¥–æ-—Ñ–æ–Ω–µ–º–∞–º–∏ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filelist_path}")
            logger.info(f"üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –≤ —Ñ–∞–π–ª–µ: {stats['total_records']:,}")
            if stats.get("new_records", 0) > 0:
                logger.info(f"üìä –ù–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π –¥–æ–±–∞–≤–ª–µ–Ω–æ: {stats['new_records']:,}")
            
            if stats.get("stats_path"):
                logger.info(f"üìä –ü–æ–¥—Ä–æ–±–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {stats['stats_path']}")
            
            # –í–∞–∂–Ω–æ–µ –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ –æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å—Ç–∞—Ç—å–µ
            logger.info("\n" + "="*60)
            logger.info("‚úÖ –ì–û–¢–û–í–û! –ü–°–ï–í–î–û-–§–û–ù–ï–ú–ù–´–ï –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û–°–¢–ò –°–ì–ï–ù–ï–†–ò–†–û–í–ê–ù–´")
            logger.info("="*60)
            logger.info("üìù –§–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –¥–ª—è VITS:")
            logger.info(f"   {filelist_path}")
            logger.info("üìã –§–æ—Ä–º–∞—Ç –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏:")
            logger.info("   <–ø—É—Ç—å_–∫_–∞—É–¥–∏–æ>|<–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å_–ø—Å–µ–≤–¥–æ-—Ñ–æ–Ω–µ–º>|<speaker_id>")
            logger.info("")
            logger.info("üéØ –≠–¢–ò –î–ê–ù–ù–´–ï –ì–û–¢–û–í–´ –î–õ–Ø:")
            logger.info("   ‚Ä¢ Pre-training VITS –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –Ω–∞ unlabeled speech")
            logger.info("   ‚Ä¢ Transfer learning –¥–ª—è low-resource TTS")
            logger.info("   ‚Ä¢ Fine-tuning –Ω–∞ small labeled dataset (–∫–∞–∫ –≤ —Å—Ç–∞—Ç—å–µ)")
            logger.info("")
            logger.info("üí° –°–û–í–ï–¢ –ò–ó –°–¢–ê–¢–¨–ò:")
            logger.info("   –î–ª—è single-speaker TTS –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—Å–µ–≥–æ 10 –º–∏–Ω—É—Ç labeled –¥–∞–Ω–Ω—ã—Ö")
            logger.info("   –¥–ª—è fine-tuning –ø–æ—Å–ª–µ pre-training –Ω–∞ pseudo-phonemes")
            logger.info("="*60)
    
    except KeyboardInterrupt:
        logger.info("\n" + "="*60)
        logger.info("üõë –ü–†–û–ì–†–ê–ú–ú–ê –ü–†–ï–†–í–ê–ù–ê –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï–ú")
        logger.info("="*60)
        logger.info("‚úÖ –í—Å–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")
        logger.info("‚úÖ –ü—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–º –∑–∞–ø—É—Å–∫–µ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—Å—è —Å –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ç–æ—á–∫–∏")
        logger.info("="*60)
        sys.exit(0)
    
    except Exception as e:
        logger.exception(f"üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {str(e)}")
        sys.exit(1)
    
    logger.info("\n" + "="*60)
    logger.info("üéâ –ü–†–û–ì–†–ê–ú–ú–ê –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù–ê!")
    logger.info("="*60)
    logger.info("‚úÖ –ü—Å–µ–≤–¥–æ-—Ñ–æ–Ω–µ–º–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≥–æ—Ç–æ–≤—ã –¥–ª—è pre-training VITS")
    logger.info("‚úÖ –ü–æ–ª–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ –∏–∑ —Å—Ç–∞—Ç—å–∏ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–æ")
    logger.info("="*60)


if __name__ == "__main__":
    main()